{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#Loading dataset\n",
   "id": "6763da877035de58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T12:41:16.832425Z",
     "start_time": "2025-05-17T12:41:16.827531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "5e2e9edb8f44522f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model #1\n",
    "Written in pure python."
   ],
   "id": "44b306c59f2f8ed6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T12:41:56.160221Z",
     "start_time": "2025-05-17T12:41:56.155243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LinearRegression():\n",
    "    def __init__(self, params = 8):\n",
    "        self.w = [random.random() for _ in range(params)]\n",
    "        self.b = 0.0\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_hat = []\n",
    "        for x, w in zip(X, self.w):\n",
    "            y_hat.append(sum(x * w) + self.b)\n",
    "        return y_hat\n",
    "\n",
    "    def gradients(self, x, y):\n",
    "        m = len(x)\n",
    "        y_hat = self.predict(x)\n",
    "        dj_dw = []\n",
    "        dj_db = []\n",
    "\n",
    "        for i in range(m):\n",
    "            error = (y_hat[i] - y[i]) / m\n",
    "            for j in range(len(self.w)):\n",
    "                dj_dw.append(error * x[i][j])\n",
    "            dj_db.append(error)\n",
    "        return dj_dw, dj_db\n",
    "\n",
    "    def Losses(self, x, y):\n",
    "        m = len(x)\n",
    "        y_hat = self.predict(x)\n",
    "        error = [Y_hat - y for Y_hat, y in zip(y_hat, y)]\n",
    "        mae = sum(abs(er for er in error)) / m\n",
    "        mse = sum(er**2 for er in error) / m\n",
    "        rmse = math.sqrt(mse)\n",
    "        return mae, mse, rmse\n",
    "\n",
    "    def gradient_descent(self, x, y, alpha = 0.001):\n",
    "        dj_dw, dj_db = self.gradients(x, y)\n",
    "        self.w = [W - alpha*dw for W, dw in zip(self.w, dj_dw)]\n",
    "        self.b -= alpha * dj_db\n",
    "        return self.Losses(x, y)\n",
    "\n"
   ],
   "id": "6a97d9ac56659962",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T12:41:58.192648Z",
     "start_time": "2025-05-17T12:41:58.186655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, X, Y, epoch, lr):\n",
    "    mse = []\n",
    "    mae = []\n",
    "    rmse = []\n",
    "    for i in range(epoch):\n",
    "        a, b, c = model.gradient_descent(X, Y, lr)\n",
    "        mse.append(b)\n",
    "        mae.append(a)\n",
    "        rmse.append(c)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(mse, label=\"Mean Squared Error\", color=\"red\", linestyle=\"-\")\n",
    "    plt.plot(mae, label=\"Mean Absolute Error\", color=\"blue\", linestyle=\"-\")\n",
    "    plt.plot(rmse, label=\"Root Mean Squared Error\", color=\"green\", linestyle=\"-\")\n",
    "    plt.show()"
   ],
   "id": "ce6e10fc5bceffbb",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "Regressor = LinearRegression()\n",
    "train(Regressor, X, Y)"
   ],
   "id": "1d4a68c67ad73224"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model 2\n",
    "Using Numpy\n"
   ],
   "id": "232d2bc653b5ae74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LinearRegression_np():\n",
    "    def __init__(self, params = 8):\n",
    "        self.w = np.random.randn(params)\n",
    "        self.b = 0.0    #ts is useful for deep learning Imma try to use it here les see\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_hat = np.dot(X, self.w).sum() + self.b\n",
    "        return y_hat\n",
    "\n",
    "    def gradients(self, X, y):\n",
    "        m = len(X)"
   ],
   "id": "1f28442b6b8c8f9d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
